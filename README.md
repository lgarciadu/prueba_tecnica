# Weather Data Product

Un Data Product completo para la extracciÃ³n, transformaciÃ³n y carga (ETL) de datos climÃ¡ticos desde APIs externas hacia una base de datos MySQL.

## ğŸ“‹ Requisitos

- **Docker** (versiÃ³n 20.10+)
- **Python** (versiÃ³n 3.10+)
- **pip** (gestor de paquetes de Python)

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Levantar MySQL con Docker

```bash
# Levantar el servicio MySQL
docker compose up -d

# Verificar que el contenedor estÃ© funcionando
docker compose ps

# Ver logs del contenedor (opcional)
docker compose logs mysql
```

### 2. Instalar Dependencias de Python

```bash
# Navegar al directorio ETL
cd etl

# Crear entorno virtual
python -m venv .venv

# Activar entorno virtual
# En Linux/Mac:
source .venv/bin/activate
# En Windows:
# .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### 3. Configurar Variables de Entorno

```bash
# Copiar archivo de ejemplo
cp env.example .env

# Editar archivo .env con tus valores reales
# Especialmente importante: configurar API_KEY
nano .env  # o tu editor preferido
```

**Variables importantes a configurar:**
- `DB_HOST`: Host de MySQL (por defecto: 127.0.0.1)
- `DB_PORT`: Puerto de MySQL (por defecto: 3306)
- `DB_USER`: Usuario de MySQL
- `DB_PASSWORD`: ContraseÃ±a de MySQL
- `DB_NAME`: Nombre de la base de datos
- `API_BASE`: URL base para API archive (ETL batch)
- `API_BASE_FORECAST`: URL base para API forecast (ETL streaming, opcional, default: https://api.open-meteo.com/v1/forecast)
- `MAX_WORKERS`: NÃºmero de workers paralelos (por defecto: 4 para streaming, 8 para batch)
- `STREAMING_BATCH_SIZE`: TamaÃ±o de lote para streaming (por defecto: 10)

## ğŸƒâ€â™‚ï¸ Uso

### Ejecutar el Job ETL (Batch/HistÃ³rico)

```bash
# EjecuciÃ³n normal (escribe a la base de datos)
python etl_weather.py

# EjecuciÃ³n de prueba (no escribe a la base de datos)
python etl_weather.py --dry-run
```

### Ejecutar el Job ETL (Streaming/Forecast)

El ETL en modo streaming procesa datos de forecast en tiempo real y los guarda inmediatamente:

```bash
# EjecuciÃ³n Ãºnica (escribe a la base de datos)
python etl_weather_streaming.py

# EjecuciÃ³n de prueba (no escribe a la base de datos)
python etl_weather_streaming.py --dry-run

# EjecuciÃ³n continua cada hora (3600 segundos)
python etl_weather_streaming.py --interval 3600

# EjecuciÃ³n continua cada 15 minutos
python etl_weather_streaming.py --interval 900
```

**Diferencias entre Batch y Streaming:**
- **Batch (`etl_weather.py`)**: Procesa datos histÃ³ricos (archive API), guarda en lotes grandes
- **Streaming (`etl_weather_streaming.py`)**: Procesa forecast en tiempo real, guarda inmediatamente en lotes pequeÃ±os

### Verificar Duplicados

```bash
# Verificar que no hay duplicados en la base de datos
python check_duplicates_mysql.py
```

**CÃ³digos de salida:**
- `0`: No se encontraron duplicados
- `2`: Se encontraron duplicados

## ğŸ“Š Estructura del Proyecto

```
weather-data-product/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n de Docker
â”œâ”€â”€ mysql/
â”‚   â””â”€â”€ init.sql               # Script de inicializaciÃ³n de BD
â”œâ”€â”€ config/
â”‚   â””â”€â”€ sites_sample.json      # Sitios meteorolÃ³gicos de ejemplo
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ etl_weather.py         # Job ETL principal (batch/histÃ³rico)
â”‚   â”œâ”€â”€ etl_weather_streaming.py  # Job ETL en modo streaming
â”‚   â”œâ”€â”€ check_duplicates_mysql.py  # Verificador de duplicados
â”‚   â”œâ”€â”€ requirements.txt       # Dependencias Python
â”‚   â””â”€â”€ env.example           # Variables de entorno de ejemplo
â””â”€â”€ docs/
    â””â”€â”€ architecture.md        # DocumentaciÃ³n tÃ©cnica
```

## ğŸ”„ AutomatizaciÃ³n

### EjecuciÃ³n PeriÃ³dica con Cron

Para automatizar la ejecuciÃ³n del ETL, puedes configurar un cron job:

```bash
# Editar crontab
crontab -e

# Ejecutar cada hora (ejemplo)
0 * * * * cd /ruta/al/proyecto/etl && source .venv/bin/activate && python etl_weather.py

# Ejecutar cada 6 horas
0 */6 * * * cd /ruta/al/proyecto/etl && source .venv/bin/activate && python etl_weather.py
```

### Monitoreo y Alertas

Recomendamos implementar:
- Logs estructurados (JSON) para facilitar el anÃ¡lisis
- Alertas por email/Slack cuando el job falla
- Dashboard para monitorear mÃ©tricas de calidad de datos

## â˜ï¸ Despliegue en ProducciÃ³n

### OpciÃ³n 1: Google Cloud Platform

1. **Cloud SQL**: Migrar de MySQL local a Cloud SQL
2. **Cloud Dataflow**: Ejecutar el ETL como job de Dataflow
3. **Cloud Scheduler**: Programar ejecuciones periÃ³dicas
4. **BigQuery**: Almacenar datos histÃ³ricos para anÃ¡lisis

### OpciÃ³n 2: AWS

1. **RDS MySQL**: Base de datos gestionada
2. **Lambda + EventBridge**: ETL serverless
3. **S3 + Athena**: Almacenamiento y consultas

### ConfiguraciÃ³n para ProducciÃ³n

1. **Variables de entorno**: Usar secretos gestionados (Secret Manager)
2. **Logging**: Configurar Cloud Logging o CloudWatch
3. **Monitoreo**: Implementar alertas y mÃ©tricas
4. **Escalabilidad**: Ajustar `MAX_WORKERS` segÃºn recursos disponibles

## ğŸ› ï¸ Desarrollo

### Estructura de la Base de Datos

La tabla `weather_observations` incluye:
- **Clave primaria**: `id` (auto-incremental)
- **Clave Ãºnica**: `(site_id, source, observation_time)` para idempotencia
- **Campos de auditorÃ­a**: `audit_created_*`, `audit_updated_*`
- **Datos raw**: `raw_payload` (JSON) para trazabilidad

### CaracterÃ­sticas del ETL

- **Idempotencia**: Re-ejecutar el job no crea duplicados
- **ParalelizaciÃ³n**: Procesa mÃºltiples sitios simultÃ¡neamente
- **Reintentos**: Manejo automÃ¡tico de errores de red
- **Logging**: InformaciÃ³n detallada de ejecuciÃ³n
- **Dry-run**: Modo de prueba sin escribir a BD

## ğŸ› SoluciÃ³n de Problemas

### Error de ConexiÃ³n a MySQL

```bash
# Verificar que MySQL estÃ© corriendo
docker compose ps

# Ver logs de MySQL
docker compose logs mysql

# Reiniciar MySQL
docker compose restart mysql
```

### Error de API Key

```bash
# Verificar que .env estÃ© configurado
cat .env | grep API_KEY

# Obtener API key gratuita en: https://openweathermap.org/api
```

### Verificar Duplicados

```bash
# Ejecutar verificador
python check_duplicates_mysql.py

# Si hay duplicados, revisar logs del ETL
```

## ğŸ“ˆ PrÃ³ximos Pasos

1. **ValidaciÃ³n de datos**: Implementar reglas de calidad
2. **Alertas**: Configurar notificaciones automÃ¡ticas
3. **Dashboard**: Crear visualizaciones de datos
4. **API**: Exponer datos via REST API
5. **Machine Learning**: Modelos predictivos de clima

## ğŸ“ Soporte

Para problemas o preguntas:
1. Revisar logs del ETL
2. Verificar configuraciÃ³n de variables de entorno
3. Consultar documentaciÃ³n en `docs/architecture.md`
